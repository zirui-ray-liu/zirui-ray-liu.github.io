---
layout: page
title: Spring 26 CSCI 5525 Advanced Machine Learning
description:
img:
importance: 1
category: teaching
pretty_table: true
related_publications:
---

**Instructor**: Zirui "Ray" Liu

**Time**: Spring 2026, Tues/Thurs 11:15 AM - 12:30 PM

**TA**: [Hao Li](https://nanomaoli.github.io/)

**Location**: Keller Hall 3-230

**Office Hour**: Friday 2-3PM. Hybrid. Office Number Keller 1-201, Table #3. [Zoom Link](https://umn.zoom.us/j/92450959680)


#### **Textbooks**

- [Pattern Recognition and Machine Learning (PRML)](https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf) by Chris Bishop
- [Deep Learning: Foundations and Concepts](https://www.bishopbook.com/) by Chris Bishop and Hugh Bishop
- [Gaussian Processes for Machine Learning (GPML)](https://gaussianprocess.org/gpml/) by Carl Edward Rasmussen and Christopher K. I. Williams
- [Probabilistic Machine Learning: Advanced Topics (PML)](https://probml.github.io/pml-book/book2.html) by Kevin Murphy

#### **Course Materials**

[Lecture Slides](https://forms.gle/zwGBFkCJxZKj1hWf8) (password will be sent through Canvas)

#### **Course Description**


The course is organized into three parts. In Supervised Learning, we will learn popular ML methods ranging from linear regression, boosting trees, to deep neural networks, and the Transformer architecture that powers modern AI. In Unsupervised Learning, we will learn how machines generate content through autoregressive modeling, Variational Autoencoders, and Diffusion models, which are the engines behind today's text, image and video generation systems. In Reinforcement Learning, we will learn how AI agents make decisions through policy gradients and Proximal Policy Optimization, the same techniques used to train ChatGPT and create game-playing AI.

#### **Topics Covered**

**Part I. Supervised Learning**
- Machine Learning Basics
- Linear Regression
<!-- - Boosting Trees -->
- Deep Neural Networks
  - Automatic Differentiation
  - Stochastic Optimization
  - Transformer Architectures

**Part II. Unsupervised Learning**
- Autoregressive Modeling
- Variational Autoencoders
- Diffusion

**Part III. Reinforcement Learning**
- Reinforcement Learning Basics
- Policy Gradient
- Advantage Estimation & Value Function
- Proximal Policy Optimization

#### **Grading Policy**

| Component | Weight |
|-----------|--------|
| **In-class assessments** | **40%** |
| — Quiz I & Quiz II | 15% (best score of the two is kept; lower score is dropped) |
| — Final Exam | 25% |
| **Take-home programming assignments** | **60%** |
| — Assignment 1 | 20% |
| — Assignment 2 | 20% |
| — Assignment 3 | 20% |
| Bonus points | 2 pts each, announced on Canvas |

Assignments can be completed in teams of up to 2 students.

#### **Late Policy**

Late submissions will **not** be accepted.

#### **Academic Integrity**

- Each assignment can be carried out by a team of 2 students. We encourage you to find teams early in the semester.
- Use of GenAI tools (e.g., ChatGPT) is allowed, but you must include clear citations for any parts where you use AI.
- Caveat: Research shows that relying entirely on GenAI harms learning. Focus on your own learning rather than simply putting together a submission.

#### **Course Schedule (tentative)**

*The course schedule may be changed.*

| Lecture | Date | Topic | Quiz | Homework |
|---------|------|-------|------|----------|
| Lecture 1 | 1/20 | Introduction | - | - |
| Lecture 2 | 1/22 | Linear Regression | - | - |
| Lecture 3 | 1/27 | Introduction to Probabilistic Modeling with Linear Regression  | - | - |
| Lecture 4 | 1/29 | Generalization, Model selection and Occam's razor | - | - |
| Lecture 5 | 2/3 | Bayesian Decision Theory | Quiz 1 on Linear Rgression and Bayes | HW1 is out |
| Lecture 6 | 2/5 | Reverse-mode Automated Differentation | - | - |
| Lecture 7 | 2/10 | Transformer Architecture | - | - |